<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-10-13T15:16:44.932Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>zWhat</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>强化学习(一)：强化学习基础</title>
    <link href="http://yoursite.com/2019/10/13/%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0(%E4%B8%80)%EF%BC%9A%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"/>
    <id>http://yoursite.com/2019/10/13/强化学习(一)：强化学习基础/</id>
    <published>2019-10-13T13:15:03.000Z</published>
    <updated>2019-10-13T15:16:44.932Z</updated>
    
    <content type="html"><![CDATA[<h1 id="强化学习是什么"><a href="#强化学习是什么" class="headerlink" title="强化学习是什么"></a><strong>强化学习是什么</strong></h1><p>首先看下百度的解释：</p><blockquote><p> 强化学习（Reinforcement Learning, RL），又称再励学习、评价学习或增强学习，是<a href="https://baike.baidu.com/item/机器学习/217599" target="_blank" rel="noopener">机器学习</a>的范式和<a href="https://baike.baidu.com/item/方法论/82748" target="_blank" rel="noopener">方法论</a>之一，用于描述和解决<a href="https://baike.baidu.com/item/智能体/9446647" target="_blank" rel="noopener">智能体</a>（agent）在与环境的交互过程中通过学习策略以达成回报最大化或实现特定目标的问题 。</p></blockquote><p>再说下自己理解，首先机器学习可以分为三类：监督学习（ supervised learning ），无监督学习（ unsupervised learning ），强化学习（ reinforcement learning ）。那么他们的区别在哪呢，可以举个例子来描述：监督学习就好像cs，打到人就是收益，这时你就可以把标签记作{（靶点：1），（非靶点：0）}，通过大量练习，你的命中率会越来越高；反观强化学习，它更像moba类游戏，目标很简单，摧毁水晶，但是它不像cs，每一个决策都会影响到全局，并且它的影响会复杂的多，你这一步的决策可能会给当前带来收益，但未必会给5分钟后的局面造成优势。那么既然没有标签，我们要如何训练呢，这里就是用到奖赏机制，每做一个决策，会给你一定的奖励，如何让全局的奖励最大，就是我们要去训练的。</p><h1 id="强化学习基础"><a href="#强化学习基础" class="headerlink" title="强化学习基础"></a><strong>强化学习基础</strong></h1><p>强化学习的模型如下所示：</p><p> <img src="https://img-blog.csdn.net/20180707110954489?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0xhZ3JhbmdlU0s=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="这里写图片描述"> </p><p>agent：智能体，这里指大脑</p><p>action：由agent做出的动作</p><p>reward：agent执行一个action后所得到的奖赏</p><p>enviroment：环境，这里指地球</p><p>state：agent的状态，用来决定agent下一步做什么</p><p>图中，我们并未发现state，那么接下来讨论下state具体是什么。</p><p>agent每执行一次action，我们总共可以记录以下内容：$A<del>t</del>，O<del>t+1</del>，R<del>t+1</del>$，这是agent的动作和environment所反馈给agent的信息。而state就是用来决定agent的action，它由记录下来的所有历史信息来决定，即$S<del>t</del>=f（A<del>1</del>，O<del>1</del>，R<del>1</del>，A<del>t-1</del>，O<del>t</del>，R<del>t</del>）$。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;强化学习是什么&quot;&gt;&lt;a href=&quot;#强化学习是什么&quot; class=&quot;headerlink&quot; title=&quot;强化学习是什么&quot;&gt;&lt;/a&gt;&lt;strong&gt;强化学习是什么&lt;/strong&gt;&lt;/h1&gt;&lt;p&gt;首先看下百度的解释：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt; 强
      
    
    </summary>
    
    
    
  </entry>
  
</feed>
